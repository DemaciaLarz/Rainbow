{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class DqnAgents:\n",
    "    '''Implementation of various DQN agents.\n",
    "    \n",
    "    Attributes:\n",
    "    S: numpy array with a batch of states.\n",
    "    A: numpy array with a batch of actions.\n",
    "    R: numpy array with a batch of rewards.\n",
    "    S2: numpy array with a batch of next_states.\n",
    "    T: bool, a batch of terminals.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''Initializes transition batches.'''\n",
    "        \n",
    "        self.S = None\n",
    "        self.A = None\n",
    "        self.R = None\n",
    "        self.S2 = None\n",
    "        self.T = None\n",
    "        \n",
    "    def build_dqn_graph(self, s_shape, num_a, alpha, compiled=True):\n",
    "        '''Instantiates a network graph for the DQN implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        s_shape: tuple of ints with the shape of input state.\n",
    "        num_a: int, number of available actions.\n",
    "        alpha: float, learning rate.\n",
    "        compipled: bool, True for uncompiled target net. False for\n",
    "                   compiled prediction net. \n",
    "        \n",
    "        Returns:\n",
    "        t_net: Keras model object, an uncompiled model.\n",
    "        q_net_net: Keras model object, a compiled model.\n",
    "        \n",
    "        '''\n",
    "        inputs = Input(shape=s_shape)\n",
    "        x = Dense(400, activation='relu')(inputs)\n",
    "        x = Dense(200, activation='relu')(x)\n",
    "        outputs = Dense(num_a, activation='linear')(x)\n",
    "        if not compiled:\n",
    "            t_net = Model(inputs, outputs)\n",
    "            return t_net\n",
    "        q_net = Model(inputs, outputs)\n",
    "        opt = RMSprop(learning_rate=alpha)\n",
    "        q_net.compile(optimizer=opt, loss='mse')\n",
    "        return q_net\n",
    "    \n",
    "    def build_dueling_graph(self, s_shape, num_a, alpha, batchsize, compiled=True):\n",
    "        '''Instantiates a network graph for the Dueling DQN implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        s_shape: tuple of ints with the shape of input state.\n",
    "        num_a: int, number of available actions.\n",
    "        alpha: float, learning rate.\n",
    "        batchsize: int.\n",
    "        compipled: bool, True for uncompiled target net. False for\n",
    "                   compiled prediction net. \n",
    "        \n",
    "        Returns:\n",
    "        t_net: Keras model object, an uncompiled model.\n",
    "        q_net: Keras model object, a compiled model.\n",
    "        q_net_policy: Keras model object with a seperate output.\n",
    "        \n",
    "        '''\n",
    "        inputs = Input(shape=s_shape)\n",
    "        x = Dense(400, activation='relu')(inputs)\n",
    "        x = Dense(200, activation='relu')(x)\n",
    "        v = Dense(100, activation='relu')(x)\n",
    "        v = Dense(1, activation='linear')(v)\n",
    "        a = Dense(100, activation='relu')(x)\n",
    "        a = Dense(num_a, activation='linear')(a)\n",
    "        outputs = Lambda(\n",
    "            self._subtract_mean, arguments={'num_a': num_a,\n",
    "                                            'batchsize': batchsize})([v, a])\n",
    "        if not compiled:\n",
    "            t_net = Model(inputs, outputs)\n",
    "            return t_net\n",
    "        q_net = Model(inputs, outputs)\n",
    "        q_net_policy = Model(inputs, a)\n",
    "        opt = RMSprop(learning_rate=alpha)\n",
    "        q_net.compile(optimizer=opt, loss='mse')\n",
    "        return q_net, q_net_policy\n",
    "        \n",
    "    def build_c51_graph(self, s_shape, num_a, num_atoms, alpha, compiled=True):\n",
    "        '''Instantiates a network graph for the c51 implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        s_shape: tuple of ints with the shape of input state.\n",
    "        num_a: int, number of available actions.\n",
    "        num_atoms: int, number of atoms in support.\n",
    "        alpha: float, learning rate.\n",
    "        compipled: bool, True for uncompiled target net. False for\n",
    "                   compiled prediction net. \n",
    "        \n",
    "        Returns:\n",
    "        t_net: Keras model object, an uncompiled model.\n",
    "        q_net: Keras model object, a compiled model.\n",
    "        \n",
    "        '''\n",
    "        inputs = Input(shape=s_shape)\n",
    "        x = Dense(400, activation='relu')(inputs)\n",
    "        x = Dense(200, activation='relu')(x)\n",
    "        outputs = [Dense(num_atoms, activation='softmax')(x) for _ in range(num_a)]\n",
    "        if not compiled:\n",
    "            t_net = Model(inputs, outputs)\n",
    "            return t_net\n",
    "        q_net = Model(inputs, outputs)\n",
    "        opt = RMSprop(learning_rate=alpha)\n",
    "        q_net.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "        return q_net\n",
    "    \n",
    "    def _subtract_mean(self, args, num_a, batchsize):\n",
    "        '''Final layer module in the dueling architecture.\n",
    "        \n",
    "        Arguments:\n",
    "        args: list of Keras tensor objects of layer outputs.\n",
    "        num_a: int with the number of available actions.\n",
    "        batchsize: int.\n",
    "        \n",
    "        Returns:\n",
    "        action values: Keras tensor object, the model output.\n",
    "        \n",
    "        '''\n",
    "        v, A = args\n",
    "        A_mean = tf.math.reduce_mean(A)\n",
    "        A_sub_mean = tf.math.subtract(A, A_mean)\n",
    "        V = tf.broadcast_to(v, [batchsize, num_a])\n",
    "        return tf.math.add(V, A_sub_mean)\n",
    "    \n",
    "    def policy(self, q_net, s, num_a, epsilon, c51=False):\n",
    "        '''Generating a step given some state.\n",
    "        \n",
    "        Arguments: \n",
    "        q_net: Keras model object, action value approximator.\n",
    "        s: numpy array, state agent is currently in.\n",
    "        num_a: int, number of available actions.\n",
    "        epsilon: float, e in epsilon greedy policy, exploration rate.\n",
    "        c51: bool, takes the expected values of c51 outputs if True.\n",
    "        \n",
    "        Returns:\n",
    "        a: numpy array of int, selected action.\n",
    "        \n",
    "        '''\n",
    "        if np.random.random() < epsilon:\n",
    "            action = np.random.randint(num_a)\n",
    "        else:\n",
    "            if c51:\n",
    "                z = q_net.predict([[s]])\n",
    "                q = [np.mean(z) for z in z]\n",
    "            else:\n",
    "                q = q_net.predict([[s]])[0]\n",
    "            max_a = []\n",
    "            for i, j in enumerate(q):\n",
    "                if j == np.amax(q):\n",
    "                    max_a.append(i)\n",
    "            action = np.random.choice(max_a)\n",
    "        return action\n",
    "    \n",
    "    def unpack_experience(self, transitions, batchsize, n_step=False):\n",
    "        '''Unpacks a block of sampled experience into transition pieces.\n",
    "        \n",
    "        Arguments:\n",
    "        transitions: list of tuples with a batch of sampled transitions.\n",
    "        batchsize: int.\n",
    "        n_step: bool, if to handle an n-step transition or not.\n",
    "                               \n",
    "        \n",
    "        '''\n",
    "        if n_step:\n",
    "            self.S = []\n",
    "            self.A = []\n",
    "            self.R = []\n",
    "            self.S2 = []\n",
    "            self.T = []\n",
    "            for i in range(batchsize):\n",
    "                self.S.append(transitions[i][:,:1].T)\n",
    "                self.A.append(transitions[i][:,1:2].T)\n",
    "                self.R.append(transitions[i][:,2:3].T)\n",
    "                self.S2.append(transitions[i][:,3:4].T)\n",
    "                self.T.append(transitions[i][:,4:5].T)\n",
    "            self.S = np.array(self.S).squeeze()\n",
    "            self.A = np.array(self.A).squeeze()\n",
    "            self.R = np.array(self.R).squeeze()\n",
    "            self.S2 = np.array(self.S2).squeeze()\n",
    "            self.T = np.array(self.T).squeeze()\n",
    "        else:\n",
    "            self.S = np.array([transitions[i][0] for i in range(batchsize)])\n",
    "            self.A = np.array([transitions[i][1] for i in range(batchsize)])\n",
    "            self.R = np.array([transitions[i][2] for i in range(batchsize)])\n",
    "            self.S2 = np.array([transitions[i][3] for i in range(batchsize)])\n",
    "            self.T = np.array([transitions[i][4] for i in range(batchsize)])\n",
    "    \n",
    "    def dqn_targets(self, q_net, t_net, gamma, batchsize):\n",
    "        '''Computes the TD error target term in the DQN implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        q_net: Keras model object, action value approximator.\n",
    "        t_net: Keras model object, target model.\n",
    "        gamma: float, the discount factor.\n",
    "        \n",
    "        Returns:\n",
    "        targets: numpy array with a batch of targets.\n",
    "        S: numpy array with a batch of states.\n",
    "        \n",
    "        '''\n",
    "        t_nexts = t_net.predict(self.S2)\n",
    "        t_maxs = [np.amax(t_nexts[i]) for i in range(batchsize)]\n",
    "        deltas = []\n",
    "        for i in range(batchsize):\n",
    "            r = self.R[i]\n",
    "            t = self.T[i]\n",
    "            if t:\n",
    "                deltas.append(r)\n",
    "            else:\n",
    "                deltas.append(r + (gamma * t_maxs[i]))\n",
    "        targets = q_net.predict(self.S)\n",
    "        self.deltas = deltas\n",
    "        self.targets = targets\n",
    "        for i in range(batchsize):\n",
    "            targets[i, self.A[i]] = deltas[i]\n",
    "        return self.targets, self.S\n",
    "        \n",
    "    def ddqn_targets(self, q_net, t_net, gamma, batchsize):\n",
    "        '''Computes the target term in the Double DQN implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        q_net: Keras model object, action value approximator.\n",
    "        t_net: Keras model object, target model.\n",
    "        gamma: float, the discount factor.\n",
    "        batchsize: int.\n",
    "        \n",
    "        Returns:\n",
    "        targets: numpy array with a batch of targets.\n",
    "        deltas: list with TD errors.\n",
    "        S: numpy array with a batch of states.\n",
    "        \n",
    "        '''\n",
    "        q_nexts = q_net.predict(self.S2)\n",
    "        q_maxs = [np.argmax(q_nexts[i]) for i in range(batchsize)]\n",
    "        t_nexts = t_net.predict(self.S2)\n",
    "        deltas = []\n",
    "        for i in range(batchsize):\n",
    "            r = self.R[i]\n",
    "            t = self.T[i]\n",
    "            if t:\n",
    "                deltas.append(r)\n",
    "            else:\n",
    "                deltas.append(r + (gamma * t_nexts[i, q_maxs[i]]))\n",
    "        targets = q_net.predict(self.S)\n",
    "        for i in range(batchsize):\n",
    "            targets[i, self.A[i]] = deltas[i]\n",
    "        return targets, deltas, self.S\n",
    "    \n",
    "    def per_targets(self, q_net, t_net, gamma, batchsize, is_w):\n",
    "        '''Computes the target term in the PER DQN implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        q_net: Keras model object, action value approximator.\n",
    "        t_net: Keras model object, target model.\n",
    "        gamma: float, the discount factor.\n",
    "        is_w: numpy array of floats, importance sampling weights.\n",
    "        \n",
    "        Returns:\n",
    "        targets: numpy array with a batch of targets.\n",
    "        deltas: list with TD errors.\n",
    "        S: numpy array with a batch of states.\n",
    "        \n",
    "        '''\n",
    "        q_nexts = q_net.predict(self.S2)\n",
    "        q_maxs = [np.argmax(q_nexts[i]) for i in range(batchsize)]\n",
    "        t_nexts = t_net.predict(self.S2)\n",
    "        deltas = []\n",
    "        for i in range(batchsize):\n",
    "            r = self.R[i]\n",
    "            t = self.T[i]\n",
    "            if t:\n",
    "                deltas.append(r)\n",
    "            else:\n",
    "                deltas.append(r + (gamma * t_nexts[i][q_maxs[i]]))\n",
    "        targets = tmp = q_net.predict(self.S)\n",
    "        deltas2 = []\n",
    "        for i in range(batchsize):\n",
    "            targets[i, self.A[i]] = deltas[i]\n",
    "            d = deltas[i] - tmp[i][self.A[i]]\n",
    "            deltas2.append(0.5 * d ** 2 if abs(d) < 1.0 else abs(d) - 0.5)\n",
    "        return targets, deltas2, self.S\n",
    "    \n",
    "    def multi_step_targets(self, q_net, t_net, gamma, batchsize, n_steps):\n",
    "        '''Computes the TD error target term in the n-step implementation.\n",
    "        \n",
    "        Arguments:\n",
    "        q_net: Keras model object, action value approximator.\n",
    "        t_net: Keras model object, target model.\n",
    "        gamma: float, the discount factor.\n",
    "        n_steps: int with the number of n_steps.\n",
    "        \n",
    "        Returns:\n",
    "        targets: numpy array with a batch of targets.\n",
    "        S_t: numpy array with a batch of states.\n",
    "        \n",
    "        '''  \n",
    "        G_t = []\n",
    "        S_t = []\n",
    "        S2_t_n = []\n",
    "        for i in range(batchsize):\n",
    "            g = 0\n",
    "            for j in range(1, n_steps):\n",
    "                if not self.T[i, j]:\n",
    "                    g += gamma**j-1 * self.R[i, j]\n",
    "            G_t.append(g)\n",
    "            S_t.append(self.S[i, 0])\n",
    "            S2_t_n.append(self.S2[i, -1])\n",
    "        S_t = np.array(S_t)\n",
    "        S2_t_n = np.array(S2_t_n)\n",
    "        targs_t_n = t_net.predict([S2_t_n])\n",
    "        targs_max = [np.amax(targs_t_n[i]) for i in range(batchsize)]\n",
    "        deltas = []\n",
    "        for i in range(batchsize):\n",
    "            r = G_t[i]\n",
    "            t = self.T[i, 0]\n",
    "            if t:\n",
    "                deltas.append(r)\n",
    "            else:\n",
    "                deltas.append(r + (gamma * targs_max[i]))\n",
    "        targets = q_net.predict([S_t])\n",
    "        for i in range(batchsize):\n",
    "            targets[i, self.A[i, 0]] = deltas[i]\n",
    "        return targets, S_t\n",
    "    \n",
    "    def c51_targets(self, q_net, t_net, num_a, v_min, v_max, num_atoms, gamma, batchsize):\n",
    "        '''Computes and projects a c51 target distribution.\n",
    "        \n",
    "        Arguments:\n",
    "        t_net: Keras Model object, target model.\n",
    "        num_a: int, number of available actions.\n",
    "        v_min: float, minimum in the target support.\n",
    "        v_max: float, maximum in the target support.\n",
    "        num_atoms: int, number of atoms.\n",
    "        gamma: float, discount factor.\n",
    "        batchsize: int.\n",
    "        \n",
    "        Returns:\n",
    "        targets: numpy array with a batch of targets.\n",
    "        S_t, numpy array with a batch of states.\n",
    "        \n",
    "        '''\n",
    "        z = q_net.predict(self.S2)\n",
    "        z_ = t_net.predict(self.S2)      \n",
    "        Z = np.linspace(v_min, v_max, num_atoms)\n",
    "        delta_z = (v_max - v_min) / (num_atoms - 1)\n",
    "        m_probs = [np.zeros((batchsize, num_atoms)) for _ in range(num_a)]\n",
    "        for i in range(batchsize):\n",
    "                if self.T[i]:\n",
    "                    Z_rb = [max(v_min, min(self.R[i], v_max)) for z in Z]\n",
    "                    B = [(z - v_min) / delta_z for z in Z_rb]\n",
    "                    m_l = [math.floor(b) for b in B]\n",
    "                    m_u = [math.ceil(b) for b in B]\n",
    "                    for j in range(num_atoms):\n",
    "                        m_probs[self.A[i]][i][m_l[j]] = (m_u[j] - B[j])\n",
    "                        m_probs[self.A[i]][i][m_u[j]] = (B[j] - m_l[j])\n",
    "                else:\n",
    "                    Z_rb = [max(v_min, min(self.R[i] + (gamma * z), v_max)) for z in Z]\n",
    "                    B = [(z - v_min) / delta_z for z in Z_rb]\n",
    "                    m_l = [math.floor(b) for b in B]\n",
    "                    m_u = [math.ceil(b) for b in B]\n",
    "                    expectations = []\n",
    "                    for a in range(num_a):\n",
    "                        expectation = 0\n",
    "                        for ind, val in enumerate(z[a][i]):\n",
    "                            expectation += ind * val\n",
    "                        expectations.append(expectation)\n",
    "                    z_idx = np.argmax(expectations)\n",
    "                    for j in range(num_atoms):\n",
    "                        m_probs[self.A[i]][i][m_l[j]] = z_[z_idx][i][j] * (m_u[j] - B[j])\n",
    "                        m_probs[self.A[i]][i][m_u[j]] = z_[z_idx][i][j] * (B[j] - m_l[j])\n",
    "        return targets, self.S\n",
    "    \n",
    "class SumTree:\n",
    "    '''Builds the sum tree structure for PER.\n",
    "    \n",
    "    Attributes:\n",
    "    zero_idx (int): leaf starting indicie in the tree.\n",
    "    step (int): tracks the number of added leaves.\n",
    "    leaf_count (int): number of leaves that have non zero values.\n",
    "    sum_tree (numpy array): sum tree data structure.\n",
    "    data (numpy array): stored transitions data structure.\n",
    "        \n",
    "    '''\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        '''Initializes SumTree.\n",
    "        \n",
    "        Arguments:\n",
    "        capacity (int): number of leaves in the tree.\n",
    "        \n",
    "        '''\n",
    "        self.capacity = capacity\n",
    "        self.zero_idx = self.capacity - 1\n",
    "        self.step = 0\n",
    "        self.leaf_count = 0\n",
    "        self.sum_tree = np.zeros(((2 * capacity) - 1))\n",
    "        self.data = np.zeros((capacity), dtype=object)\n",
    "        \n",
    "    def get_leaf_count(self):\n",
    "        '''Gets the number of leaves in the tree.'''\n",
    "        return self.leaf_count\n",
    "    \n",
    "    def get_leaf_sum(self):\n",
    "        '''Gets the total sum of the leaves.'''\n",
    "        return self.sum_tree[0]   \n",
    "    \n",
    "    def propagate(self, parent, value):\n",
    "        '''Propagates a leaf value or difference to the root.\n",
    "        \n",
    "        Arguments:\n",
    "        parent (int): parent of the leaf.\n",
    "        value (float): value to be propagated.\n",
    "              \n",
    "        '''\n",
    "        while (parent - 1) != 0:\n",
    "            self.sum_tree[parent - 1] += value\n",
    "            parent = parent // 2\n",
    "        self.sum_tree[parent - 1] += value\n",
    "        \n",
    "    def add_leaf(self, priority, transition):\n",
    "        '''Adds a leaf to the sum tree and a transition to data.\n",
    "        \n",
    "        - If the leaf_count equals the capacity, the leaf\n",
    "          with the longest duration in the tree will be \n",
    "          replaced with the new.\n",
    "        - If capacity is full, correspondning transition\n",
    "          in data will be removed and replaced with the new.\n",
    "        \n",
    "        Arguments:\n",
    "        priority (int or float): value to be stored as a leaf.\n",
    "        transition (tuple): holds (s1, a, r, s2, t).\n",
    "        \n",
    "        '''\n",
    "        # identify the parent to the leaf in question\n",
    "        parent = (self.zero_idx + self.step + 1) // 2\n",
    "        # if the tree is of full capacity\n",
    "        if self.get_leaf_count() == self.capacity:\n",
    "            # get difference between added and removed leaves\n",
    "            current_value = self.sum_tree[self.zero_idx + self.step]\n",
    "            diff = abs(current_value - priority)\n",
    "            # set if propagated difference should be added or subtracted\n",
    "            if priority < current_value:\n",
    "                diff = -diff\n",
    "            self.propagate(parent, diff)\n",
    "        # if the tree is not full\n",
    "        else: \n",
    "            self.propagate(parent, priority)\n",
    "        # insert priority in the tree\n",
    "        self.sum_tree[self.zero_idx + self.step] = priority\n",
    "        # insert the transition in the data array\n",
    "        self.data[self.step] = transition\n",
    "        # update the step parameter\n",
    "        if self.step == (self.capacity - 1):\n",
    "            self.step = 0\n",
    "        else:\n",
    "            self.step += 1\n",
    "        # update leaf count\n",
    "        if self.leaf_count < self.capacity:\n",
    "            self.leaf_count += 1\n",
    "        else: \n",
    "            self.leaf_count = self.capacity\n",
    "            \n",
    "    def update_leaf(self, priority, idx):\n",
    "        '''Updates a current leaf.\n",
    "        \n",
    "        Arguments:\n",
    "        priority (float): value to be updated.\n",
    "        idx (int): indicie of leaf to be updated.\n",
    "        \n",
    "        '''\n",
    "        current_value = self.sum_tree[self.zero_idx + idx]\n",
    "        diff = abs(current_value - priority)\n",
    "        if priority < current_value:\n",
    "            diff = -diff\n",
    "        parent = (self.zero_idx + idx + 1) // 2\n",
    "        # propagate difference up to the root node\n",
    "        self.propagate(parent, diff)\n",
    "        # replace the leaf value\n",
    "        self.sum_tree[self.zero_idx + idx] = priority\n",
    "        \n",
    "    def get_leaf(self, s):\n",
    "        '''Sample a leaf given a segment sample.\n",
    "        \n",
    "        Arguments:\n",
    "        segment_sample (int): uniformly sampled integer.\n",
    "        \n",
    "        Returns:\n",
    "        priority (float): the leaf value.\n",
    "        idx (int): indicie of the leaf.\n",
    "        transition (tuple): transition corresponding to the leaf.\n",
    "        \n",
    "        '''\n",
    "        idx = 1\n",
    "        while idx <= self.zero_idx:\n",
    "            # identify children\n",
    "            left = idx * 2\n",
    "            right = left + 1\n",
    "            # compare s and go left or right\n",
    "            if s > self.sum_tree[left - 1]:\n",
    "                s = s - self.sum_tree[left - 1]\n",
    "                idx = right\n",
    "            else: \n",
    "                idx = left\n",
    "        priority = self.sum_tree[idx - 1]\n",
    "        idx = idx - self.zero_idx - 1\n",
    "        transition = self.data[idx]\n",
    "        return priority, idx, transition\n",
    "    \n",
    "\n",
    "class PrioritizedExperienceReplay:\n",
    "    '''Implements the prioritized replay.\n",
    "        \n",
    "        Attributes:\n",
    "        sum_tree (class object): the sum tree class.\n",
    "        max_priority (float): highest priority added to the tree.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                capacity,\n",
    "                batchsize,\n",
    "                alpha=0.6,\n",
    "                beta=0.4,\n",
    "                beta_increment=0.001,\n",
    "                epsilon=0.001):\n",
    "        '''Initializes PrioritizedExperienceReplay.\n",
    "        \n",
    "        Arguments:\n",
    "        capacity (int): sum tree size.\n",
    "        batchsize (int): batchsize.\n",
    "        alpha (float): priority exponent.\n",
    "        beta (float): importance sampling exponent.\n",
    "        beta_increment (float): beta increment rate.\n",
    "        epsilon (float): priority additive constant. \n",
    "        \n",
    "        '''\n",
    "        self.alpha = 0.6\n",
    "        self.beta = 0.4\n",
    "        self.beta_increment = 0.001\n",
    "        self.epsilon = 0.001\n",
    "        self.batchsize = batchsize\n",
    "        self.sum_tree = SumTree(capacity)\n",
    "        self.max_priority = 1.\n",
    "        \n",
    "    def len_memory(self):\n",
    "        '''Gives the current size of the memory.'''\n",
    "        return self.sum_tree.get_leaf_count()\n",
    "\n",
    "    def store_transition(self, delta, transition):\n",
    "        '''Defines a priority and stores it in sum tree.\n",
    "\n",
    "        Arguments:\n",
    "        delta (float): TD error from training.\n",
    "        transition (tuple or list): consist of (s1, a, r, s2, t)\n",
    "\n",
    "        '''\n",
    "        # define the priority as abs((delta) + epsilon)**alpha \n",
    "        priority = (abs(delta) + self.epsilon) ** self.alpha\n",
    "        # set priority to max\n",
    "        priority = max(priority, self.max_priority)\n",
    "        # add the priority to the sum tree\n",
    "        self.sum_tree.add_leaf(priority, transition)\n",
    "        # update max_priority\n",
    "        self.max_priority = max(priority, self.max_priority)\n",
    "    \n",
    "    def sample_transition(self):\n",
    "        '''Samples a batch of transitions based on their proportional priorities.\n",
    "        \n",
    "        2. split up the range [0, tot_p] in batchsize equally sized segments.\n",
    "        3. sample uniformly from each range and obtain a batch of idxs.\n",
    "        4. obtain a batch of transitions according to sampled idxs.\n",
    "        5. adjust the beta parameter.\n",
    "        6. compute segment probabilities and importance sampling weights.\n",
    "        \n",
    "        #### \n",
    "        RETURNS:\n",
    "        transitions (list of tuples): sampled transitions of size batchsize.\n",
    "        idxs (list): indicies of sampled priorities and transitions.\n",
    "        is_w (list): importance sampling weights\n",
    "        \n",
    "        '''\n",
    "        priorities = []\n",
    "        idxs = []\n",
    "        transitions = []\n",
    "        total_priority = self.sum_tree.get_leaf_sum()\n",
    "        segment_size = total_priority // self.batchsize\n",
    "        self.s = segment_size\n",
    "        for i in range(self.batchsize):\n",
    "            # sample uniformly from within each segmentself.\n",
    "            s = np.random.randint(i * segment_size, i * segment_size + segment_size)\n",
    "            priority, idx, transition = self.sum_tree.get_leaf(s)\n",
    "            priorities.append(priority)\n",
    "            idxs.append(idx)\n",
    "            transitions.append(self.sum_tree.data[idx])\n",
    "        # adjust beta according to global step\n",
    "        self.beta = min(1., self.beta + self.beta_increment)\n",
    "        # compute probabilities and importance sampling weights\n",
    "        tot_p = self.sum_tree.get_leaf_sum()\n",
    "        probabilities = priorities / total_priority\n",
    "        is_w = np.power(self.sum_tree.get_leaf_count() * probabilities, -self.beta)\n",
    "        is_w = np.nan_to_num(is_w)\n",
    "        is_w = is_w / max(is_w)\n",
    "        if type(transitions[0]) != tuple:\n",
    "            transitions[0] = transitions[1]\n",
    "        return transitions, idxs, is_w\n",
    "    \n",
    "    def update_priorities(self, deltas, idxs):\n",
    "        '''Takes TD errors from training and updates priorities.\n",
    "        \n",
    "        Arguments:\n",
    "        deltas (list or tuple): TD errors from training.\n",
    "        idxs (list): indicies of priorities from current batch.\n",
    "        \n",
    "        '''\n",
    "        for i in range(self.batchsize):\n",
    "            priority = (abs(deltas[i]) + self.epsilon) ** self.alpha  \n",
    "            idx = idxs[i]\n",
    "            self.sum_tree.update_leaf(priority, idx)\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "        \n",
    "class ExperienceReplay:\n",
    "    '''Implements an experience memory replay.\n",
    "        \n",
    "    Attributes:\n",
    "    memory (list): the memory data structure.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, capacity, batchsize):\n",
    "        '''\n",
    "        Arguments:\n",
    "        capacity (int): size of memory.\n",
    "        batchsize (int): batchsize.\n",
    "\n",
    "        '''\n",
    "        self.capacity = capacity\n",
    "        self.batchsize = batchsize\n",
    "        self.memory = []\n",
    "        \n",
    "    def len_memory(self):\n",
    "        '''Current size of the memory.\n",
    "        \n",
    "        Returns:\n",
    "        int, length of the memory.\n",
    "        '''\n",
    "        return len(self.memory)\n",
    "        \n",
    "    def store_transition(self, _, transition):\n",
    "        '''Loads a transition into the memory from the back.\n",
    "        \n",
    "        - If the memory is full, the transition with the longest\n",
    "          duration in the memory will be removed from the front.\n",
    "        \n",
    "        Arguments:\n",
    "        transition (tuple): a transition of (s1, a, r, s2, t)\n",
    "        \n",
    "        '''\n",
    "        if len(self.memory) == self.capacity:\n",
    "            del self.memory[0]\n",
    "        self.memory.append(transition)\n",
    "        \n",
    "    def sample_transition(self, n_step=False):\n",
    "        '''Samples a batch of transitions from memory.\n",
    "        \n",
    "        Arguments:\n",
    "        n_step: bool, if True a tuple with n-steps and n_horizon.\n",
    "        \n",
    "        Returns:\n",
    "        (numpy array): sampled transitions.\n",
    "        \n",
    "        '''\n",
    "        samples = []\n",
    "        if n_step:\n",
    "            if len(self.memory) < self.capacity:\n",
    "                for i in range(self.batchsize):\n",
    "                    n_samples = [self.memory[\n",
    "                            np.random.randint(len(self.memory))] for _ in range(n_step[0])]\n",
    "                    samples.append(n_samples)\n",
    "                transitions = np.array(samples)\n",
    "                return transitions\n",
    "            else:\n",
    "                for i in range(self.batchsize):\n",
    "                    min_h = (n_step[1]//2) + 10\n",
    "                    max_h = self.capacity - min_h\n",
    "                    n_samples = [self.memory[\n",
    "                            np.random.randint(len(self.memory))] for _ in range(n_step[0])]\n",
    "                    samples.append(n_samples)\n",
    "                transitions = np.array(samples)\n",
    "                return transitions\n",
    "                \n",
    "        for i in range(self.batchsize):\n",
    "            sample = self.memory[np.random.randint(len(self.memory))]\n",
    "            samples.append(sample)\n",
    "        transitions = np.array(samples)\n",
    "        return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
